{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-19 09:47:09.416466: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-19 09:47:09.416511: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>MON1 CL DDM (?A)</th>\n",
       "      <th>MON1 CL RF (dB)</th>\n",
       "      <th>MON1 DS DDM (?A)</th>\n",
       "      <th>MON1 DS RF (dB)</th>\n",
       "      <th>MON1 NF DDM (?A)</th>\n",
       "      <th>MON1 NF RF (dB)</th>\n",
       "      <th>MON1 CLR DDM (?A)</th>\n",
       "      <th>MON1 CLR RF (dB)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-28 14:11:19</td>\n",
       "      <td>2.02</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.29</td>\n",
       "      <td>-3.18</td>\n",
       "      <td>0.19</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-28 14:16:19</td>\n",
       "      <td>1.74</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.29</td>\n",
       "      <td>-2.89</td>\n",
       "      <td>0.19</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-28 14:21:20</td>\n",
       "      <td>1.74</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.29</td>\n",
       "      <td>-3.18</td>\n",
       "      <td>0.19</td>\n",
       "      <td>2.60</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-28 14:26:20</td>\n",
       "      <td>0.29</td>\n",
       "      <td>-39.90</td>\n",
       "      <td>-76.94</td>\n",
       "      <td>-39.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-39.90</td>\n",
       "      <td>-322.78</td>\n",
       "      <td>-35.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-28 14:31:20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-39.90</td>\n",
       "      <td>-76.94</td>\n",
       "      <td>-39.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-39.90</td>\n",
       "      <td>-322.49</td>\n",
       "      <td>-35.61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Timestamp  MON1 CL DDM (?A)  MON1 CL RF (dB)  MON1 DS DDM (?A)  \\\n",
       "0 2022-01-28 14:11:19              2.02             0.32              0.87   \n",
       "1 2022-01-28 14:16:19              1.74             0.32              0.87   \n",
       "2 2022-01-28 14:21:20              1.74             0.32              0.87   \n",
       "3 2022-01-28 14:26:20              0.29           -39.90            -76.94   \n",
       "4 2022-01-28 14:31:20              0.00           -39.90            -76.94   \n",
       "\n",
       "   MON1 DS RF (dB)  MON1 NF DDM (?A)  MON1 NF RF (dB)  MON1 CLR DDM (?A)  \\\n",
       "0             0.29             -3.18             0.19               2.31   \n",
       "1             0.29             -2.89             0.19               2.31   \n",
       "2             0.29             -3.18             0.19               2.60   \n",
       "3           -39.90              0.00           -39.90            -322.78   \n",
       "4           -39.90              0.00           -39.90            -322.49   \n",
       "\n",
       "   MON1 CLR RF (dB)  \n",
       "0              0.34  \n",
       "1              0.34  \n",
       "2              0.34  \n",
       "3            -35.61  \n",
       "4            -35.61  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import sep\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "df = pd.read_csv('FormattedData/train.csv', sep = ',' , header=0, parse_dates=['Timestamp'])\n",
    "\n",
    "df.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp            0\n",
       "MON1 CL DDM (?A)     0\n",
       "MON1 CL RF (dB)      0\n",
       "MON1 DS DDM (?A)     0\n",
       "MON1 DS RF (dB)      0\n",
       "MON1 NF DDM (?A)     0\n",
       "MON1 NF RF (dB)      0\n",
       "MON1 CLR DDM (?A)    0\n",
       "MON1 CLR RF (dB)     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index = pd.to_datetime(df['Timestamp'].astype('datetime64').astype(int), format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "#Filling in null values\n",
    "df = df.replace('?', np.nan)\n",
    "df.isnull().sum()\n",
    "\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1166/1594298119.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[i] = s_s\n",
      "/tmp/ipykernel_1166/1594298119.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[i] = s_s\n",
      "/tmp/ipykernel_1166/1594298119.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[i] = s_s\n",
      "/tmp/ipykernel_1166/1594298119.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[i] = s_s\n",
      "/tmp/ipykernel_1166/1594298119.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[i] = s_s\n",
      "/tmp/ipykernel_1166/1594298119.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[i] = s_s\n",
      "/tmp/ipykernel_1166/1594298119.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[i] = s_s\n",
      "/tmp/ipykernel_1166/1594298119.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[i] = s_s\n",
      "/tmp/ipykernel_1166/1594298119.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[i] = s_s\n",
      "/tmp/ipykernel_1166/1594298119.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[i] =s_s\n",
      "/tmp/ipykernel_1166/1594298119.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[i] =s_s\n",
      "/tmp/ipykernel_1166/1594298119.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[i] =s_s\n",
      "/tmp/ipykernel_1166/1594298119.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[i] =s_s\n",
      "/tmp/ipykernel_1166/1594298119.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[i] =s_s\n",
      "/tmp/ipykernel_1166/1594298119.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[i] =s_s\n",
      "/tmp/ipykernel_1166/1594298119.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[i] =s_s\n",
      "/tmp/ipykernel_1166/1594298119.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[i] =s_s\n",
      "/tmp/ipykernel_1166/1594298119.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[i] =s_s\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = df[1:2529], df[2529:]\n",
    "\n",
    "#Scale values from -1 to 1\n",
    "train = train_df\n",
    "scalers = {}\n",
    "\n",
    "for i in train_df.columns:\n",
    "    scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "    s_s = scaler.fit_transform(train[i].values.reshape(-1,1))\n",
    "    s_s = np.reshape(s_s, len(s_s))\n",
    "    scalers['scaler_' + i] = scaler\n",
    "    train[i] = s_s\n",
    "\n",
    "test = test_df\n",
    "for i in train_df.columns:\n",
    "    scaler = scalers['scaler_' + i]\n",
    "    s_s = scaler.transform(test[i].values.reshape(-1,1))\n",
    "    s_s = np.reshape(s_s, len(s_s))\n",
    "    scalers['scaler_' + i] = scaler\n",
    "    test[i] =s_s\n",
    "\n",
    "\n",
    "#Convert series to samples\n",
    "def split_series (series, n_past, n_future):\n",
    "    #\n",
    "    #n_past => number of past observations\n",
    "    #\n",
    "    #n_future => number of future observations\n",
    "    #\n",
    "    #\n",
    "    X, y = list(), list()\n",
    "    for window_start in range(len(series)):\n",
    "        past_end = window_start + n_past\n",
    "        future_end = past_end + n_future\n",
    "        if future_end >len(series):\n",
    "            break\n",
    "        \n",
    "    # slicing the past and future parts of the window\n",
    "        past, future = series[window_start:past_end, :], series[past_end:future_end, :]\n",
    "        X.append(past)\n",
    "        y.append(future)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "n_past = 10\n",
    "n_future = 5\n",
    "n_features = 9\n",
    "\n",
    "X_train, y_train = split_series(train.values,n_past, n_future)\n",
    "#X_train = X_train.reshape((X_train.shape[0], X_train.shape[1],n_features))\n",
    "#y_train = y_train.reshape((y_train.shape[0], y_train.shape[1], n_features))\n",
    "X_test, y_test = split_series(test.values,n_past, n_future)\n",
    "#X_test = X_test.reshape((X_test.shape[0], X_test.shape[1],n_features))\n",
    "#y_test = y_test.reshape((y_test.shape[0], y_test.shape[1], n_features))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-19 09:54:10.810631: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-04-19 09:54:10.810679: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-04-19 09:54:10.810714: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (DESKTOP-8JQCUIJ): /proc/driver/nvidia/version does not exist\n",
      "2022-04-19 09:54:10.811077: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 10, 9)]      0           []                               \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  [(None, 10, 100),    44000       ['input_2[0][0]']                \n",
      "                                 (None, 100),                                                     \n",
      "                                 (None, 100)]                                                     \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)                  [(None, 100),        80400       ['lstm_2[0][0]']                 \n",
      "                                 (None, 100),                                                     \n",
      "                                 (None, 100)]                                                     \n",
      "                                                                                                  \n",
      " repeat_vector_1 (RepeatVector)  (None, 5, 100)      0           ['lstm_3[0][0]']                 \n",
      "                                                                                                  \n",
      " lstm_4 (LSTM)                  (None, 5, 100)       80400       ['repeat_vector_1[0][0]',        \n",
      "                                                                  'lstm_2[0][1]',                 \n",
      "                                                                  'lstm_2[0][2]']                 \n",
      "                                                                                                  \n",
      " lstm_5 (LSTM)                  (None, 5, 100)       80400       ['lstm_4[0][0]',                 \n",
      "                                                                  'lstm_3[0][1]',                 \n",
      "                                                                  'lstm_3[0][2]']                 \n",
      "                                                                                                  \n",
      " time_distributed_1 (TimeDistri  (None, 5, 9)        909         ['lstm_5[0][0]']                 \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 286,109\n",
      "Trainable params: 286,109\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# E1D1\n",
    "# n_features ==> no of features at each timestep in the data.\n",
    "#\n",
    "encoder_inputs = tf.keras.layers.Input(shape=(n_past, n_features))\n",
    "encoder_l1 = tf.keras.layers.LSTM(100, return_state=True)\n",
    "encoder_outputs1 = encoder_l1(encoder_inputs)\n",
    "encoder_states1 = encoder_outputs1[1:]\n",
    "#\n",
    "decoder_inputs = tf.keras.layers.RepeatVector(n_future)(encoder_outputs1[0])\n",
    "#\n",
    "decoder_l1 = tf.keras.layers.LSTM(100, return_sequences=True)(decoder_inputs,initial_state = encoder_states1)\n",
    "decoder_outputs1 = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(n_features))(decoder_l1)\n",
    "#\n",
    "model_e1d1 = tf.keras.models.Model(encoder_inputs,decoder_outputs1)\n",
    "#\n",
    "#print(model_e1d1.summary())\n",
    "\n",
    "# E2D2\n",
    "# n_features ==> no of features at each timestep in the data.\n",
    "#\n",
    "encoder_inputs = tf.keras.layers.Input(shape=(n_past, n_features))\n",
    "encoder_l1 = tf.keras.layers.LSTM(100,return_sequences = True, return_state=True)\n",
    "encoder_outputs1 = encoder_l1(encoder_inputs)\n",
    "encoder_states1 = encoder_outputs1[1:]\n",
    "encoder_l2 = tf.keras.layers.LSTM(100, return_state=True)\n",
    "encoder_outputs2 = encoder_l2(encoder_outputs1[0])\n",
    "encoder_states2 = encoder_outputs2[1:]\n",
    "#\n",
    "decoder_inputs = tf.keras.layers.RepeatVector(n_future)(encoder_outputs2[0])\n",
    "#\n",
    "decoder_l1 = tf.keras.layers.LSTM(100, return_sequences=True)(decoder_inputs,initial_state = encoder_states1)\n",
    "decoder_l2 = tf.keras.layers.LSTM(100, return_sequences=True)(decoder_l1,initial_state = encoder_states2)\n",
    "decoder_outputs2 = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(n_features))(decoder_l2)\n",
    "#\n",
    "model_e2d2 = tf.keras.models.Model(encoder_inputs,decoder_outputs2)\n",
    "#\n",
    "model_e2d2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 10, 9)]      0           []                               \n",
      "                                                                                                  \n",
      " lstm_8 (LSTM)                  [(None, 10, 100),    44000       ['input_4[0][0]']                \n",
      "                                 (None, 100),                                                     \n",
      "                                 (None, 100)]                                                     \n",
      "                                                                                                  \n",
      " lstm_9 (LSTM)                  [(None, 100),        80400       ['lstm_8[0][0]']                 \n",
      "                                 (None, 100),                                                     \n",
      "                                 (None, 100)]                                                     \n",
      "                                                                                                  \n",
      " repeat_vector_3 (RepeatVector)  (None, 5, 100)      0           ['lstm_9[0][0]']                 \n",
      "                                                                                                  \n",
      " lstm_10 (LSTM)                 (None, 5, 100)       80400       ['repeat_vector_3[0][0]',        \n",
      "                                                                  'lstm_8[0][1]',                 \n",
      "                                                                  'lstm_8[0][2]']                 \n",
      "                                                                                                  \n",
      " lstm_11 (LSTM)                 (None, 5, 100)       80400       ['lstm_10[0][0]',                \n",
      "                                                                  'lstm_9[0][1]',                 \n",
      "                                                                  'lstm_9[0][2]']                 \n",
      "                                                                                                  \n",
      " time_distributed_3 (TimeDistri  (None, 5, 9)        909         ['lstm_11[0][0]']                \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 286,109\n",
      "Trainable params: 286,109\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0.99231213, 0.29471144, 0.9818646 , ..., 0.9532724 ,\n",
       "         0.9625031 , 0.97704405],\n",
       "        [0.99359137, 0.29864204, 0.9772228 , ..., 0.9507662 ,\n",
       "         0.95885265, 0.9723835 ],\n",
       "        [1.0006138 , 0.29907253, 0.9783205 , ..., 0.95069075,\n",
       "         0.95827246, 0.9673355 ],\n",
       "        [0.9994216 , 0.30118072, 0.97635716, ..., 0.94889134,\n",
       "         0.95379966, 0.9647023 ],\n",
       "        [0.9934177 , 0.30420575, 0.97259474, ..., 0.94827837,\n",
       "         0.9494043 , 0.965648  ]],\n",
       "\n",
       "       [[0.99181443, 0.32322633, 0.9825298 , ..., 0.9547569 ,\n",
       "         0.9645328 , 0.9773594 ],\n",
       "        [0.993723  , 0.32738748, 0.97814554, ..., 0.95319355,\n",
       "         0.9622385 , 0.97362494],\n",
       "        [1.0008597 , 0.32685825, 0.9792493 , ..., 0.95330137,\n",
       "         0.961871  , 0.9685934 ],\n",
       "        [0.9997797 , 0.32769558, 0.9773335 , ..., 0.9515223 ,\n",
       "         0.95738226, 0.9658291 ],\n",
       "        [0.9938752 , 0.32941997, 0.97360677, ..., 0.9508355 ,\n",
       "         0.9528861 , 0.9665986 ]],\n",
       "\n",
       "       [[0.99200594, 0.341304  , 0.9826854 , ..., 0.9552291 ,\n",
       "         0.96565557, 0.9774636 ],\n",
       "        [0.99414045, 0.34522626, 0.9783989 , ..., 0.95433533,\n",
       "         0.9642262 , 0.9743522 ],\n",
       "        [1.0012838 , 0.34382787, 0.9794566 , ..., 0.9546348 ,\n",
       "         0.96403384, 0.9693439 ],\n",
       "        [1.0002435 , 0.34367713, 0.97752964, ..., 0.9529437 ,\n",
       "         0.95956373, 0.9665074 ],\n",
       "        [0.99438506, 0.34445003, 0.9737946 , ..., 0.9522787 ,\n",
       "         0.9550243 , 0.9671812 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1.4636406 , 0.2540644 , 0.9628351 , ..., 0.9315835 ,\n",
       "         0.935167  , 0.9626221 ],\n",
       "        [1.4777973 , 0.27484837, 0.97217524, ..., 0.935059  ,\n",
       "         0.9266725 , 0.9587704 ],\n",
       "        [1.4859812 , 0.2905236 , 0.98318094, ..., 0.9393746 ,\n",
       "         0.9226453 , 0.95501965],\n",
       "        [1.4806715 , 0.3057021 , 0.98723876, ..., 0.9409305 ,\n",
       "         0.9155315 , 0.9534614 ],\n",
       "        [1.468544  , 0.31887555, 0.98690885, ..., 0.9423535 ,\n",
       "         0.90868354, 0.9553053 ]],\n",
       "\n",
       "       [[1.4651163 , 0.27564147, 0.964377  , ..., 0.9332668 ,\n",
       "         0.93939453, 0.96427476],\n",
       "        [1.4797069 , 0.29681885, 0.97394854, ..., 0.93744653,\n",
       "         0.9310741 , 0.9609056 ],\n",
       "        [1.4876957 , 0.3117433 , 0.98488367, ..., 0.9419096 ,\n",
       "         0.92650187, 0.95710313],\n",
       "        [1.4821419 , 0.32580525, 0.9888753 , ..., 0.9434075 ,\n",
       "         0.9187915 , 0.9553207 ],\n",
       "        [1.4698023 , 0.3377901 , 0.9884648 , ..., 0.9446638 ,\n",
       "         0.91142523, 0.95685756]],\n",
       "\n",
       "       [[1.4652029 , 0.29012337, 0.96449643, ..., 0.9343613 ,\n",
       "         0.94200253, 0.96585816],\n",
       "        [1.4807769 , 0.31190613, 0.974188  , ..., 0.9393881 ,\n",
       "         0.93358654, 0.962657  ],\n",
       "        [1.4888968 , 0.32651347, 0.98491555, ..., 0.9441282 ,\n",
       "         0.92838466, 0.9586304 ],\n",
       "        [1.4833267 , 0.33993995, 0.9888104 , ..., 0.94565153,\n",
       "         0.9201221 , 0.95650274],\n",
       "        [1.4709367 , 0.35118386, 0.9883575 , ..., 0.9467896 ,\n",
       "         0.91234475, 0.95765245]]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# E1D1\n",
    "# n_features ==> no of features at each timestep in the data.\n",
    "#\n",
    "encoder_inputs = tf.keras.layers.Input(shape=(n_past, n_features))\n",
    "encoder_l1 = tf.keras.layers.LSTM(100, return_state=True)\n",
    "encoder_outputs1 = encoder_l1(encoder_inputs)\n",
    "encoder_states1 = encoder_outputs1[1:]\n",
    "#\n",
    "decoder_inputs = tf.keras.layers.RepeatVector(n_future)(encoder_outputs1[0])\n",
    "#\n",
    "decoder_l1 = tf.keras.layers.LSTM(100, return_sequences=True)(decoder_inputs,initial_state = encoder_states1)\n",
    "decoder_outputs1 = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(n_features))(decoder_l1)\n",
    "#\n",
    "model_e1d1 = tf.keras.models.Model(encoder_inputs,decoder_outputs1)\n",
    "#\n",
    "#print(model_e1d1.summary())\n",
    "\n",
    "# E2D2\n",
    "# n_features ==> no of features at each timestep in the data.\n",
    "#\n",
    "encoder_inputs = tf.keras.layers.Input(shape=(n_past, n_features))\n",
    "encoder_l1 = tf.keras.layers.LSTM(100,return_sequences = True, return_state=True)\n",
    "encoder_outputs1 = encoder_l1(encoder_inputs)\n",
    "encoder_states1 = encoder_outputs1[1:]\n",
    "encoder_l2 = tf.keras.layers.LSTM(100, return_state=True)\n",
    "encoder_outputs2 = encoder_l2(encoder_outputs1[0])\n",
    "encoder_states2 = encoder_outputs2[1:]\n",
    "#\n",
    "decoder_inputs = tf.keras.layers.RepeatVector(n_future)(encoder_outputs2[0])\n",
    "#\n",
    "decoder_l1 = tf.keras.layers.LSTM(100, return_sequences=True)(decoder_inputs,initial_state = encoder_states1)\n",
    "decoder_l2 = tf.keras.layers.LSTM(100, return_sequences=True)(decoder_l1,initial_state = encoder_states2)\n",
    "decoder_outputs2 = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(n_features))(decoder_l2)\n",
    "#\n",
    "model_e2d2 = tf.keras.models.Model(encoder_inputs,decoder_outputs2)\n",
    "#\n",
    "model_e2d2.summary()\n",
    "\n",
    "\n",
    "#Training models. Adam optimizer/Huber loss\n",
    "reduce_lr = tf.keras.callbacks.LearningRateScheduler(lambda x: 1e-3 * 0.90 ** x)\n",
    "model_e1d1.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.Huber())\n",
    "history_e1d1=model_e1d1.fit(X_train,y_train,epochs=25,validation_data=(X_test,y_test),batch_size=32,verbose=0,callbacks=[reduce_lr])\n",
    "model_e2d2.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.Huber())\n",
    "history_e2d2=model_e2d2.fit(X_train,y_train,epochs=25,validation_data=(X_test,y_test),batch_size=32,verbose=0,callbacks=[reduce_lr])\n",
    "\n",
    "\n",
    "#Predict on test samples\n",
    "pred_e1d1=model_e1d1.predict(X_test)\n",
    "pred_e2d2=model_e2d2.predict(X_test)\n",
    "\n",
    "pred_e1d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp\n",
      "Value 1 :\n",
      "MAE-E1D1 :  39803507265678.53, MAE-E2D2 :  35050410124771.863\n",
      "Value 2 :\n",
      "MAE-E1D1 :  35472446058219.91, MAE-E2D2 :  33677440209371.824\n",
      "Value 3 :\n",
      "MAE-E1D1 :  32122214290454.26, MAE-E2D2 :  33918050084673.547\n",
      "Value 4 :\n",
      "MAE-E1D1 :  33143469574184.504, MAE-E2D2 :  35917312993834.98\n",
      "Value 5 :\n",
      "MAE-E1D1 :  36495045471192.12, MAE-E2D2 :  39844539000312.27\n",
      "MON1 CL DDM (?A)\n",
      "Value 1 :\n",
      "MAE-E1D1 :  0.15026561405347733, MAE-E2D2 :  0.19983444473017808\n",
      "Value 2 :\n",
      "MAE-E1D1 :  0.1756961705143324, MAE-E2D2 :  0.2060936359276517\n",
      "Value 3 :\n",
      "MAE-E1D1 :  0.1959744896865696, MAE-E2D2 :  0.19654568179218077\n",
      "Value 4 :\n",
      "MAE-E1D1 :  0.22023908787879384, MAE-E2D2 :  0.19186680786851515\n",
      "Value 5 :\n",
      "MAE-E1D1 :  0.24348439794807608, MAE-E2D2 :  0.19336182270648966\n",
      "MON1 CL RF (dB)\n",
      "Value 1 :\n",
      "MAE-E1D1 :  0.5019971606266475, MAE-E2D2 :  0.29562392809489335\n",
      "Value 2 :\n",
      "MAE-E1D1 :  0.4260967318013035, MAE-E2D2 :  0.4337120356329671\n",
      "Value 3 :\n",
      "MAE-E1D1 :  0.3016477139925577, MAE-E2D2 :  0.444724702184393\n",
      "Value 4 :\n",
      "MAE-E1D1 :  0.281160127745507, MAE-E2D2 :  0.485856799851762\n",
      "Value 5 :\n",
      "MAE-E1D1 :  0.31591759312708034, MAE-E2D2 :  0.542729719234056\n",
      "MON1 DS DDM (?A)\n",
      "Value 1 :\n",
      "MAE-E1D1 :  1.5610321007970407, MAE-E2D2 :  0.9296670396394734\n",
      "Value 2 :\n",
      "MAE-E1D1 :  1.5283363106044157, MAE-E2D2 :  0.877920918679674\n",
      "Value 3 :\n",
      "MAE-E1D1 :  1.4562218774498272, MAE-E2D2 :  1.1371450249676627\n",
      "Value 4 :\n",
      "MAE-E1D1 :  1.3908795392106172, MAE-E2D2 :  1.412109405866712\n",
      "Value 5 :\n",
      "MAE-E1D1 :  1.240948772895337, MAE-E2D2 :  1.634746210234968\n",
      "MON1 DS RF (dB)\n",
      "Value 1 :\n",
      "MAE-E1D1 :  0.18316878341410828, MAE-E2D2 :  0.2336091336838396\n",
      "Value 2 :\n",
      "MAE-E1D1 :  0.3342240226574121, MAE-E2D2 :  0.35824948234219717\n",
      "Value 3 :\n",
      "MAE-E1D1 :  0.4410391190585205, MAE-E2D2 :  0.4711449320535296\n",
      "Value 4 :\n",
      "MAE-E1D1 :  0.5162432530713112, MAE-E2D2 :  0.5570260936630383\n",
      "Value 5 :\n",
      "MAE-E1D1 :  0.5370883626190769, MAE-E2D2 :  0.5949928105899837\n",
      "MON1 NF DDM (?A)\n",
      "Value 1 :\n",
      "MAE-E1D1 :  0.38553469582474315, MAE-E2D2 :  0.6431641316183973\n",
      "Value 2 :\n",
      "MAE-E1D1 :  0.41181524502345723, MAE-E2D2 :  0.8733606697812454\n",
      "Value 3 :\n",
      "MAE-E1D1 :  0.47706569075285216, MAE-E2D2 :  0.9623617890114675\n",
      "Value 4 :\n",
      "MAE-E1D1 :  0.5619652598539754, MAE-E2D2 :  0.9260345347157279\n",
      "Value 5 :\n",
      "MAE-E1D1 :  0.6513169937067022, MAE-E2D2 :  0.8337320192634681\n",
      "MON1 NF RF (dB)\n",
      "Value 1 :\n",
      "MAE-E1D1 :  0.6284860493596149, MAE-E2D2 :  0.35997870840216034\n",
      "Value 2 :\n",
      "MAE-E1D1 :  0.6049960053040687, MAE-E2D2 :  0.4597441391303578\n",
      "Value 3 :\n",
      "MAE-E1D1 :  0.561224557842784, MAE-E2D2 :  0.5243237357778806\n",
      "Value 4 :\n",
      "MAE-E1D1 :  0.5655034374411876, MAE-E2D2 :  0.6032064073026778\n",
      "Value 5 :\n",
      "MAE-E1D1 :  0.562534259784246, MAE-E2D2 :  0.6415751252531698\n",
      "MON1 CLR DDM (?A)\n",
      "Value 1 :\n",
      "MAE-E1D1 :  5.308541088377603, MAE-E2D2 :  6.716180678928516\n",
      "Value 2 :\n",
      "MAE-E1D1 :  6.383989535559908, MAE-E2D2 :  4.642525465623859\n",
      "Value 3 :\n",
      "MAE-E1D1 :  6.760128797042646, MAE-E2D2 :  4.67097565265449\n",
      "Value 4 :\n",
      "MAE-E1D1 :  7.592284019260448, MAE-E2D2 :  5.256121874910471\n",
      "Value 5 :\n",
      "MAE-E1D1 :  8.350712008222866, MAE-E2D2 :  5.678791423165307\n",
      "MON1 CLR RF (dB)\n",
      "Value 1 :\n",
      "MAE-E1D1 :  0.38008761886985426, MAE-E2D2 :  0.5764503332143894\n",
      "Value 2 :\n",
      "MAE-E1D1 :  0.4633217900947715, MAE-E2D2 :  0.4416567533983859\n",
      "Value 3 :\n",
      "MAE-E1D1 :  0.5512496662121247, MAE-E2D2 :  0.36255566102610026\n",
      "Value 4 :\n",
      "MAE-E1D1 :  0.6017510593902533, MAE-E2D2 :  0.3642874375256878\n",
      "Value 5 :\n",
      "MAE-E1D1 :  0.5902865448177921, MAE-E2D2 :  0.38435706832365996\n"
     ]
    }
   ],
   "source": [
    "#Reverse scale values\n",
    "for index,i in enumerate(train_df.columns):\n",
    "    scaler = scalers['scaler_'+i]\n",
    "    #pred1_e1d1[:,:,index]=scaler.inverse_transform(pred1_e1d1[:,:,index])\n",
    "    pred_e1d1[:,:,index]=scaler.inverse_transform(pred_e1d1[:,:,index])\n",
    "    #pred1_e2d2[:,:,index]=scaler.inverse_transform(pred1_e2d2[:,:,index])\n",
    "    pred_e2d2[:,:,index]=scaler.inverse_transform(pred_e2d2[:,:,index])\n",
    "    y_train[:,:,index]=scaler.inverse_transform(y_train[:,:,index])\n",
    "    y_test[:,:,index]=scaler.inverse_transform(y_test[:,:,index])\n",
    "\n",
    "\n",
    "for index,i in enumerate(train_df.columns):\n",
    "  print(i)\n",
    "  for j in range(1,6):\n",
    "    print(\"Value\",j,\":\")\n",
    "    print(\"MAE-E1D1 : \",mean_absolute_error(y_test[:,j-1,index],pred_e1d1[:,j-1,index]),end=\", \")\n",
    "    print(\"MAE-E2D2 : \",mean_absolute_error(y_test[:,j-1,index],pred_e2d2[:,j-1,index]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4519571cc91a93d0c72c28044431df44a89b4f51d710bc5492c4fa68ab57f462"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
